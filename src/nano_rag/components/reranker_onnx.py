#!/usr/bin/env python
# -*- coding: UTF-8 -*-

'''
@Project ï¼šnano_rag 
@File    ï¼šreranker_onnx.py
@Author  ï¼šfengzhengxiong
@Date    ï¼š2025/12/30 09:50 
'''

import logging
import asyncio
import torch
from typing import List, Tuple

from optimum.onnxruntime import ORTModelForSequenceClassification
from transformers import AutoTokenizer
from langsmith import traceable

from langchain_core.documents import Document
from ..core.interfaces import RerankerInterface
from ..core.exceptions import InitializationError, RetrievalError
from ..config.models import BGERerankerConfig

logger = logging.getLogger(__name__)


class ONNXBGEReranker(RerankerInterface):
    """
    åŸºäºŽ ONNX Runtime çš„é«˜æ€§èƒ½é‡æŽ’åºå®žçŽ° (INT8 Quantized)ã€‚
    """

    def __init__(self, config: BGERerankerConfig):
        self._config = config
        self._model = None
        self._tokenizer = None

        try:
            logger.info(f"ðŸš€ Initializing ONNX Reranker from: {config.model_name}")

            # 1. åŠ è½½ Tokenizer
            self._tokenizer = AutoTokenizer.from_pretrained(config.model_name)

            # 2. åŠ è½½ ONNX æ¨¡åž‹ (è‡ªåŠ¨å¯»æ‰¾ model_quantized.onnx)
            # è¿™é‡Œçš„ file_name å¿…é¡»å¯¹åº”è½¬æ¢è„šæœ¬é‡Œç”Ÿæˆçš„æ–‡ä»¶å
            self._model = ORTModelForSequenceClassification.from_pretrained(
                config.model_name,
                file_name="model_quantized.onnx"
            )

            logger.info("âœ… ONNX Reranker initialized successfully (Backend: ONNX Runtime).")

        except Exception as e:
            raise InitializationError("ONNXBGEReranker", f"Failed to load ONNX model from {config.model_name}", e)

    @property
    def config(self) -> BGERerankerConfig:
        return self._config

    @traceable(name="BGE Reranker", run_type="retriever")  # ã€æ–°å¢žè¿™è¡Œã€‘
    def rerank(self, query: str, documents: List[Document]) -> List[Tuple[Document, float]]:
        """åŒæ­¥æŽ¨ç† (CPU INT8)"""
        if not documents: return []

        try:
            # 1. æž„é€ è¾“å…¥å¯¹
            pairs = [[query, doc.page_content] for doc in documents]

            # 2. Tokenize (è½¬ä¸º Tensor)
            # truncation=True, max_length=512 é™åˆ¶é•¿åº¦
            inputs = self._tokenizer(
                pairs,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            )

            # 3. æŽ¨ç† (ONNX Runtime)
            # outputs.logits å½¢çŠ¶ä¸º [batch_size, 1]
            with torch.no_grad():
                outputs = self._model(**inputs)

            # 4. æå–åˆ†æ•° (Sigmoid å¤„ç†)
            logits = outputs.logits
            if logits.shape[1] == 1:
                scores = torch.sigmoid(logits).view(-1).tolist()
            else:
                # æŸäº›æ¨¡åž‹å¯èƒ½è¾“å‡º [batch, 2]ï¼Œå–æ­£ç±»åˆ†æ•°
                scores = torch.softmax(logits, dim=1)[:, 1].tolist()

            # 5. æŽ’åº
            results = list(zip(documents, scores))
            results.sort(key=lambda x: x[1], reverse=True)

            return results

        except Exception as e:
            raise RetrievalError("ONNX Reranking process failed", e)

    async def arerank(self, query: str, documents: List[Document]) -> List[Tuple[Document, float]]:
        """å¼‚æ­¥åŒ…è£…"""
        if not documents: return []
        try:
            return await asyncio.to_thread(self.rerank, query, documents)
        except Exception as e:
            raise RetrievalError("Async ONNX reranking failed", e)